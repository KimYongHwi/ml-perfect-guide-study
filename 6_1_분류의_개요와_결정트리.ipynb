{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6-1. 분류의 개요와 결정트리.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPVXrKDlZ5Rid3dtxicJgPz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KimYongHwi/ml-perfect-guide-study/blob/main/6_1_%EB%B6%84%EB%A5%98%EC%9D%98_%EA%B0%9C%EC%9A%94%EC%99%80_%EA%B2%B0%EC%A0%95%ED%8A%B8%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XRDZKpU3gKw"
      },
      "source": [
        "### 분류 알고리즘\n",
        "\n",
        "분류(Classification)는 학습 데이터로 주어진 데이터의 feature와 label값을 머신러닝 알고리즘으로 학습해 모델을 생성하고, 이렇게 생성된 모델에 새로운 데이터 값이 주어졌을 때 미지의 label값을 예측하는 것이다.\n",
        "\n",
        "**대표적인 분류 알고리즘**\n",
        "- 베이즈(Bayes) 통계와 생성 모델에 기반한 나이브 베이즈(Naive Bayes)\n",
        "- 독립변수와 종속변수의 선형 관계성에 기반한 로지스틱 회귀 (Logistic Regression with sigmoid)\n",
        "- 데이터 균일도에 따른 규칙 기반의 결정 트리 (Decisioin Tree)\n",
        "- 개별 클래스 간의 최대 분류 마진을 효과적으로 찾아주는 서포트 벡터 머신 (Support Vector Machine)\n",
        "- 근접 거리를 기준으로 하는 최소 근접 알고리즘 (Nearest Neighbor)\n",
        "- 심층 연결 기반의 신경망(Neural Network)\n",
        "- 서로 다른(또는 같은) 머신러닝 알고리즘을 결합한 앙상블(Ensemble)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8TncFxI5GED"
      },
      "source": [
        "### 결정 트리와 앙상블\n",
        "- 결정 트리는 매우 쉽고 유연하게 적용될 수 있는 알고리즘이다. 또한 데이터의 스케일링이나 정규화 등의 사전 가공의 영향이 매우 적다. 하지만 예측 성능을 향상시키기 위해 복잡한 규칙 구조를 가져야 하며, 이로 인한 과적합이 발생해 반대로 예측 성능이 저하될 수도 있다는 단점이 았다.\n",
        "- 이러한 단점이 앙상블 기법에서는 오히려 장점으로 작용한다. 앙상블은 매우 많은 여러개의 약한 학습기(즉, 예측 성능이 상대적으로 떨어지는 학습 알고리즘)을 결합해 확률적 보완과 오류가 발생한 부분에 대한 가중치를 계속 업데이트하면서 예측 성능을 향상시키는데, 결정 트리가 좋은 약한 학습기가 되기 때문이다.(GBM, XGBoost, LightGBM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0awywVlC561O"
      },
      "source": [
        "### 결정트리\n",
        "- 결정 트리 알고리즘은 데이터에 있는 규칙을 학습을 통해 자동으로 찾아내 트리(Tree) 기반의 분류 규칙을 만든다. (if-else 기반 규칙)\n",
        "- 데이터가 어떤 기준을 바탕으로 규칙을 만들어야 가장 효율적인 분류가 될 것인가가 알고리즘의 성능을 크게 좌우한다.\n",
        "\n",
        "**노드**\n",
        "\n",
        "- 루트 노드\n",
        "- 규칙 노드: 규칙조건, 규칙 노드 기반의 서브 트리 생성\n",
        "- 리프 노드: 결정된 분류값"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv8Z_YAE7JQ2"
      },
      "source": [
        "### 정보 균일도 측정 방법\n",
        "\n",
        "- **정보 이득(Information Gain)**\n",
        "\n",
        "    정보 이득은 엔트로피라는 개념을 기반으로 한다. 엔트로피는 주어진 데이터 집합의 혼잡도를 의미하는데, 서로 다른 값이 섞여 있으면 엔트로피가 높고, 같은 값이 섞여 있으면 엔트로피가 낮다. 정보 이득 지수는 1에서 엔트로피 지수를 뺀 값이다. 결정 트리는 이 정보 이득 지수로 분할 기준을 정한다. 즉, 정보 이득이 높은 속성을 기준으로 분할한다.\n",
        "\n",
        "- **지니 계수**\n",
        "\n",
        "    지니 계수는 원래 경제학에서 불평등 지수를 나타낼 때 사용하는 계수이다. 경제학자인 코라도 지니의 이름에서 딴 계수로서 0이 가장 평등하고 1로 갈수록 불평등하다. 머신러닝에 적용될 때는 지니 계수가 낮을 수록 데이터 균일도가 높은 것으로 해석되어 계수가 낮은 속성을 기준으로 분할한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlEwwtPE9Bla"
      },
      "source": [
        "### 결정 트리의 규칙 노드 생성 프로세스\n",
        "\n",
        "1. 데이터 집합의 모든 아이템이 같은 분류에 속하는지 확인\n",
        "\n",
        "2. 만약 그렇다면 리프 노드로 만들어서 분류 결정\n",
        "\n",
        "3. 만약 그렇지 않다면 데이터를 분할하는데 가장 좋은 속성과 분할 기준을 찾는다. (정보이득 or 지니계수 이용)\n",
        "\n",
        "4. 해당 속성과 분할 기준으로 데이터를 분할하여 규칙 브랜치 노드 생성\n",
        "\n",
        "5. 반복적으로 모든 데이터 집합의 뷴류가 결정될 떄 까지 위 과정을 수행\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6BFLX9193b1"
      },
      "source": [
        "### 결정 트리의 특징\n",
        "\n",
        "**장점**\n",
        "\n",
        "- 쉽고 직관적이다.\n",
        "- featur의 스케일링이나 정규화 등의 사전 가공 영향도가 크지 않다.\n",
        "\n",
        "**단점**\n",
        "\n",
        "- 과적합으로 알고리즘 성능이 떨어진다. 이를 극복하기 위해 트리의 크기를 사전에 제한하는 튜닝이 필요하다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2StiwtYx3KKz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}