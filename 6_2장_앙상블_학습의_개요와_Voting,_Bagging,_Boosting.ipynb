{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6-2장. 앙상블 학습의 개요와 Voting, Bagging, Boosting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPzoL3445ETDskoiN9L+h7e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KimYongHwi/ml-perfect-guide-study/blob/main/6_2%EC%9E%A5_%EC%95%99%EC%83%81%EB%B8%94_%ED%95%99%EC%8A%B5%EC%9D%98_%EA%B0%9C%EC%9A%94%EC%99%80_Voting%2C_Bagging%2C_Boosting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj0x5CZ9qw_B"
      },
      "source": [
        "### 앙상블 학습\n",
        "\n",
        "앙상블 학습을 통한 분류는 여러개의 분류기(Classifier)를 생성하고 그 예측을 결합함으로써 보다 정확한 최종 예측을 도출하는 기법을 말한다. 어려운 문제의 결론을 내기 위해 여러 명의 전문가로 위원회를 구성해 다양한 의견을 수렴하고 결정하듯이 앙상블 학습의 목표는 다양한 분류기의 예측 결과를 결합함으로써 단일 분류기 보다 신뢰성이 높은 예측값을 얻는것이다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBidNGRHrh_z"
      },
      "source": [
        "### 앙상블의 유형\n",
        "\n",
        "- 일반적으로 Voting, Bagging, Boosting으로 구분할 수 있으며, 이외에 Stacking등의 기법이 있다.\n",
        "- 대표적인 Bagging은 Random Forest 알고리즘이 있으며, Boosting은 에이다 부스팅, 그레디언트 부스팅, XGBoost, LightGBM등이 있다. 정형 데이터의 분류나 회귀에서는 GBM 부스팅 계열의 앙상블이 전반적으로 높은 예측 성능을 나타낸다.\n",
        "- 넓은 의미로는 서로 다른 모델을 결합한 것들을 앙상블로 지칭하기도 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC2j23nusW5J"
      },
      "source": [
        "### 앙상블의 특징\n",
        "\n",
        "- 단일 모델의 약점을 다수의 모델을 결합하여 보완한다.\n",
        "- 뛰어난 성능을 가진 모델들로만 구성하는 것보다 성능이 떨어지더라도 서로 다른 유형의 모델을 섞는 것이 오히려 전체 성능에 도움이 될 수 있다.\n",
        "- 랜덤포레스트 및 뛰어난 부스팅 알고리즘들은 모두 결정트리 알고리즘을 기반으로한 알고리즘이다.\n",
        "- 결정트리의 단점인 과적합을 수십~수천개의 많은 분류기를 결합해 보완하고 장점인 직관적인 분류 기준은 강화됐다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w8eunXbtHNY"
      },
      "source": [
        "### Voting과 Bagging 개요\n",
        "\n",
        "- Voting과 Bagging은 여러개의 분류기가 투표를 통해 최종 예측 결과를 결정하는 방식이다.\n",
        "- Voting과 Bagging의 다른 점은 Voting의 경우 일반적으로 서로 다른 알고리즘을 가진 분류기를 결합하는 것이고, Bagging의 경우 각각의 분류기가 모두 같은 유형의 알고리즘 기반이지만, 데이터 샘플링을 서로 다르게 가져가면서 학습을 수행해 투표를 진행한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkDPYOj7t191"
      },
      "source": [
        "### Voting의 유형\n",
        "\n",
        "- Hard voting: 다수의 classifier간 다수결로 최종 class를 결정한다.\n",
        "- Soft voting: 다수의 classifier들의 class 확률을 평균하여 결정한다. (predict_proba 메소드를 이용하여 class별 확률을 결정)\n",
        "- 일반적으로 Hard voting보다는 Soft voting이 예측 성능이 상대적으로 우수하여 주로 사용된다.\n",
        "- sklearn에서는 VotingClassifier 클래스를 통해 Voting을 지원한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "K58AjTojqi2R",
        "outputId": "afedb219-405e-4b56-deba-5842b6698c1b"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "data_df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
        "data_df.head(3)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.8</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.6</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.9</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.8</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.0</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.5</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "0        17.99         10.38  ...          0.4601                  0.11890\n",
              "1        20.57         17.77  ...          0.2750                  0.08902\n",
              "2        19.69         21.25  ...          0.3613                  0.08758\n",
              "\n",
              "[3 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-cmHQJuvzIJ"
      },
      "source": [
        "**개별모델 로지스틱회귀와 KNN을 Voting 방식으로 결합하여 성능 비교**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnqKz7--vBuc",
        "outputId": "acf7170c-3649-42fe-d37b-d6be9c914739"
      },
      "source": [
        "lr_clf = LogisticRegression()\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
        "\n",
        "# 개별 모델을 통해 soft voting 기반의 앙상블 모델 생성\n",
        "vo_clf = VotingClassifier(estimators=[('LR', lr_clf), ('KNN', knn_clf)], voting='soft')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2, random_state=156)\n",
        "\n",
        "# VotingClassifier 학습/예측/평가\n",
        "vo_clf.fit(X_train, y_train)\n",
        "pred = vo_clf.predict(X_test)\n",
        "print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))\n",
        "\n",
        "classifiers = [lr_clf, knn_clf]\n",
        "for classifier in classifiers:\n",
        "    classifier.fit(X_train, y_train)\n",
        "    pred = classifier.predict(X_test)\n",
        "    class_name= classifier.__class__.__name__\n",
        "    print('{0} 정확도: {1:.4f}'.format(class_name, accuracy_score(y_test , pred)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Voting 분류기 정확도: 0.9474\n",
            "LogisticRegression 정확도: 0.9386\n",
            "KNeighborsClassifier 정확도: 0.9386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ntzEnwcwo6b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}