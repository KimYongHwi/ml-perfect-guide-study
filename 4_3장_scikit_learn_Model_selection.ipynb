{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-3장. scikit-learn - Model selection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMf0dTCkBFfVKM8YxXqJWcY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KimYongHwi/ml-perfect-guide-study/blob/main/4_3%EC%9E%A5_scikit_learn_Model_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9RaQnEhuMEU"
      },
      "source": [
        "### Model Selection\n",
        "- 학습 데이터\n",
        "  - 머신러닝 알고리즘의 학습을 위해 사용\n",
        "  - 데이터의 속성들과 결정값(레이블) 모두를 가지고 있음\n",
        "  - 학습 데이터를 기반으로 머신러닝 알고리즘이 데이터 속성과 결정값의 패턴을 인지하고 학습\n",
        "\n",
        "- 테스트 데이터 세트\n",
        "  - 테스트 데이터 세트로 학습된 머신러닝 알고리즘을 테스트\n",
        "  - 테스트 데이터는 속성 데이터만 머신러닝 알고리즘에 제공하며, 머신러닝 알고리즘은 제공된 데이터를 기반으로 결정값을 예측\n",
        "  - 테스트 데이터는 학습 데이터와 별도의 데이터 세트로 제공돼야 함\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hQ_91mquMEV"
      },
      "source": [
        "#### 학습 데이터와 테스트 데이터 분리 (train_test_split)\n",
        "\n",
        "```\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.3, random_stage=121)\n",
        "```\n",
        "\n",
        "- random_state: 호출할 때마다 동일한 학습/테스트용 데이터 세트를 생성하기 위해 주어지는 난수값이다. 호출시 무작위로 데이터를 분리하므로 random_state를 지정하지 않으면 수행할 때매다 다른 학습/테스트용 데이터를 생성한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbl1jEU8uMEV",
        "outputId": "407b612e-05f3-4d80-c326-c710614682df"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "train_data = iris.data\n",
        "train_label = iris.target\n",
        "dt_clf.fit(train_data, train_label)\n",
        "\n",
        "# 학습 데이터 셋으로 예측 수행\n",
        "pred = dt_clf.predict(train_data)\n",
        "print('예측 정확도:', accuracy_score(train_label, pred))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측 정확도: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siXeTePCuMEW",
        "outputId": "dd1b03c6-355d-4956-978e-cc5139a3c9b6"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "iris_data = load_iris()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.3, random_state=121)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "pred = dt_clf.predict(X_test)\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측 정확도: 0.9556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPshEgaRuMEX"
      },
      "source": [
        "- numpy ndarray뿐만 아니라 Pandas DataFrame/Series도 train_test_split()으로 분할 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "kPrbA2CLuMEX",
        "outputId": "10e6749c-2cbc-4451-db2c-e19d87e33735"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "iris_df = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
        "iris_df['target'] = iris_data.target\n",
        "iris_df.head(3)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  ...  petal width (cm)  target\n",
              "0                5.1               3.5  ...               0.2       0\n",
              "1                4.9               3.0  ...               0.2       0\n",
              "2                4.7               3.2  ...               0.2       0\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RX4kD_8uMEX",
        "outputId": "4fbfa9e1-b71d-4e8b-8d8a-1c31ab4d4329"
      },
      "source": [
        "ftr_df = iris_df.iloc[:, :-1] # 마지막 column을 제외한 나머지 column\n",
        "tgt_df = iris_df.iloc[:, -1]  # 마지막 column\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(ftr_df, tgt_df, test_size=0.3, random_state=121)\n",
        "print(type(X_train))\n",
        "print(type(X_test))\n",
        "print(type(y_train))\n",
        "print(type(y_test))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmFn8GqguMEY",
        "outputId": "e2b8c1a7-6a72-4893-a735-bfd1f87fe21f"
      },
      "source": [
        "df_clf = DecisionTreeClassifier()\n",
        "df_clf.fit(X_train, y_train)\n",
        "pred = df_clf.predict(X_test)\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측 정확도: 0.9556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flax8Zzin9oJ"
      },
      "source": [
        "#### 학습 데이터와 테스트 데이터 분리 (train_test_split)\n",
        "\n",
        "```\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.3, random_stage=121)\n",
        "```\n",
        "\n",
        "- random_state: 호출할 때마다 동일한 학습/테스트용 데이터 세트를 생성하기 위해 주어지는 난수값이다. 호출시 무작위로 데이터를 분리하므로 random_state를 지정하지 않으면 수행할 때매다 다른 학습/테스트용 데이터를 생성한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYC-ZHw_pBfN",
        "outputId": "ee8ee934-a4ee-41a1-baf0-39d0903fda9e"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "train_data = iris.data\n",
        "train_label = iris.target\n",
        "dt_clf.fit(train_data, train_label)\n",
        "\n",
        "pred = dt_clf.predict(train_data)\n",
        "print('예측 정확도:', accuracy_score(train_label, pred))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측 정확도: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxaqISsPchpg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b103b73d-0278-42a1-9b5a-b587ef5681b1"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "iris_data = load_iris()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.3, random_state=121)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "pred = dt_clf.predict(X_test)\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측 정확도: 0.9556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kXbXt5_qiaX"
      },
      "source": [
        "- numpy ndarray뿐만 아니라 Pandas DataFrame/Series도 train_test_split()으로 분할 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "jm9gp6Pwqc4q",
        "outputId": "31129289-4840-4158-817b-171a361ede58"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "iris_df = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
        "iris_df['target'] = iris_data.target\n",
        "iris_df.head(3)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  ...  petal width (cm)  target\n",
              "0                5.1               3.5  ...               0.2       0\n",
              "1                4.9               3.0  ...               0.2       0\n",
              "2                4.7               3.2  ...               0.2       0\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLCr8-Mvs5-t",
        "outputId": "7d1718f2-45f1-4269-ca89-413ef8a4d8cc"
      },
      "source": [
        "ftr_df = iris_df.iloc[:, :-1] # 마지막 column을 제외한 나머지 column\n",
        "tgt_df = iris_df.iloc[:, -1]  # 마지막 column\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(ftr_df, tgt_df, test_size=0.3, random_state=121)\n",
        "print(type(X_train))\n",
        "print(type(X_test))\n",
        "print(type(y_train))\n",
        "print(type(y_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz6CqsQFs_FM",
        "outputId": "e55148a8-6d76-4049-9d38-facee3b20ef6"
      },
      "source": [
        "df_clf = DecisionTreeClassifier()\n",
        "df_clf.fit(X_train, y_train)\n",
        "pred = df_clf.predict(X_test)\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측 정확도: 0.9556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "126mrrAzvwNC"
      },
      "source": [
        "### 교차 검증\n",
        "- 학습 데이터 세트: 데이터세트를 분할하여 학습 데이터와 학습된 모델의 성능을 일차 평가하는 검증 데이터로 나눔\n",
        "- 검증 데이터 세트: 학습된 모델의 성능을 일차 평가하기 위한 데이터 세트\n",
        "- 테스트 데이터 세트: 모든 학습/검증 과정이 완료된 후 최종적으로 성능을 평가하기 위한 데이터세트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2DDgZ2zx-x6",
        "outputId": "7ec848b5-c0f1-47ba-946c-09ccaffdce7d"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
        "cv_accuracy = []\n",
        "kfold = KFold(n_splits=5)\n",
        "print('붓꽃 데이터 세트 크기:', features.shape[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "붓꽃 데이터 세트 크기: 150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx_d1nBoynGS",
        "outputId": "fe73167c-72e4-440f-d41b-e878b9379cd1"
      },
      "source": [
        "n_iter = 0\n",
        "\n",
        "# KFold 객체의 split 메소드를 호출하면 폴드 별 학습용, 검증용 테스트의 row 인덱스를 array로 반환\n",
        "for train_index, test_index in kfold.split(features):\n",
        "    # kfold.split 메소드로 반환된 인덱스를 이용하여 학습용, 검증용 데이터 추출\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "\n",
        "    # 학습 및 예측\n",
        "    df_clf.fit(X_train, y_train)\n",
        "    pred = df_clf.predict(X_test)\n",
        "    n_iter += 1\n",
        "\n",
        "    # 반복 마다 정확도 측정\n",
        "    accuracy = accuracy_score(y_test, pred)\n",
        "    train_size = X_train.shape[0]\n",
        "    test_size = X_test.shape[0]\n",
        "\n",
        "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
        "          .format(n_iter, accuracy, train_size, test_size))\n",
        "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
        "\n",
        "    cv_accuracy.append(accuracy)\n",
        "\n",
        "# iteration별 정확도를 합하여 평균 정확도 계산 \n",
        "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy)) \n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "#1 교차 검증 정확도 :1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#1 검증 세트 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "\n",
            "#2 교차 검증 정확도 :0.9666666666666667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
            " 54 55 56 57 58 59]\n",
            "\n",
            "#3 교차 검증 정확도 :0.8333333333333334, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
            " 84 85 86 87 88 89]\n",
            "\n",
            "#4 교차 검증 정확도 :0.9333333333333333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#4 검증 세트 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
            "\n",
            "#5 교차 검증 정확도 :0.7333333333333333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
            " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "## 평균 검증 정확도: 0.8933333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tVtf_GxxVXp"
      },
      "source": [
        "#### Stratified K fold\n",
        "- 불균형한(imbalanced) 분포도를 가진 레이블 데이터 집합을 위한 K 폴드 방식\n",
        "- 학습데이터와 검증 데이터 세트가 가지는 레이블 분포도가 유사하도록 검증 데이터 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBThApx6uXin",
        "outputId": "37bdfa95-f22f-484c-dd1e-9fd4353801c7"
      },
      "source": [
        "iris = load_iris()\n",
        "\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "iris_df['label']=iris.target\n",
        "iris_df['label'].value_counts().sort_index()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    50\n",
              "1    50\n",
              "2    50\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F56X6qol3Vyu",
        "outputId": "67233f90-bc5b-497a-eff5-131f8131210c"
      },
      "source": [
        "kfold = KFold(n_splits=3)\n",
        "# kfold.split(X)는 폴드 세트를 3번 반복할 때마다 달라지는 학습/테스트 용 데이터 로우 인덱스 번호 반환. \n",
        "n_iter =0\n",
        "for train_index, test_index  in kfold.split(iris_df):\n",
        "    n_iter += 1\n",
        "    label_train= iris_df['label'].iloc[train_index]\n",
        "    label_test= iris_df['label'].iloc[test_index]\n",
        "    print('## 교차 검증: {0}'.format(n_iter))\n",
        "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts().sort_index())\n",
        "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts().sort_index())\n",
        "\n",
        "# 학습 레이블에 검증 레이블 데이터가 없기 때문에 제대로 학습할 수 없다"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## 교차 검증: 1\n",
            "학습 레이블 데이터 분포:\n",
            " 1    50\n",
            "2    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 0    50\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 2\n",
            "학습 레이블 데이터 분포:\n",
            " 0    50\n",
            "2    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 1    50\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 3\n",
            "학습 레이블 데이터 분포:\n",
            " 0    50\n",
            "1    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    50\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAlNhpImzwh9",
        "outputId": "abb201bb-01ea-41c4-b6d7-7426dd8e57ad"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "n_iter = 0\n",
        "\n",
        "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
        "    n_iter += 1\n",
        "    label_train= iris_df['label'].iloc[train_index]\n",
        "    label_test= iris_df['label'].iloc[test_index]\n",
        "    print('## 교차 검증: {0}'.format(n_iter))\n",
        "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts().sort_index())\n",
        "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts().sort_index())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## 교차 검증: 1\n",
            "학습 레이블 데이터 분포:\n",
            " 0    33\n",
            "1    33\n",
            "2    34\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 0    17\n",
            "1    17\n",
            "2    16\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 2\n",
            "학습 레이블 데이터 분포:\n",
            " 0    33\n",
            "1    34\n",
            "2    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 0    17\n",
            "1    16\n",
            "2    17\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 3\n",
            "학습 레이블 데이터 분포:\n",
            " 0    34\n",
            "1    33\n",
            "2    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 0    16\n",
            "1    17\n",
            "2    17\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SJgESDQ0RYW",
        "outputId": "854a08ba-28f8-406d-cac6-980c781ea9a1"
      },
      "source": [
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=3)\n",
        "n_iter=0\n",
        "cv_accuracy=[]\n",
        "\n",
        "# StratifiedKFold의 split( ) 호출시 반드시 레이블 데이터 셋도 추가 입력 필요  \n",
        "for train_index, test_index  in skfold.split(features, label):\n",
        "    # split( )으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "    \n",
        "    #학습 및 예측 \n",
        "    dt_clf.fit(X_train , y_train)    \n",
        "    pred = dt_clf.predict(X_test)\n",
        "\n",
        "    # 반복 시 마다 정확도 측정 \n",
        "    n_iter += 1\n",
        "    accuracy = np.round(accuracy_score(y_test,pred), 4)\n",
        "    train_size = X_train.shape[0]\n",
        "    test_size = X_test.shape[0]\n",
        "    \n",
        "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
        "          .format(n_iter, accuracy, train_size, test_size))\n",
        "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
        "    cv_accuracy.append(accuracy)\n",
        "    \n",
        "# 교차 검증별 정확도 및 평균 정확도 계산 \n",
        "print('\\n## 교차 검증별 정확도:', np.round(cv_accuracy, 4))\n",
        "print('## 평균 검증 정확도:', np.mean(cv_accuracy)) "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "#1 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
            "#1 검증 세트 인덱스:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
            "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
            " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
            "\n",
            "#2 교차 검증 정확도 :0.94, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
            "#2 검증 세트 인덱스:[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
            "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
            " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
            "\n",
            "#3 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
            "#3 검증 세트 인덱스:[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
            "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
            " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "## 교차 검증별 정확도: [0.98 0.94 0.98]\n",
            "## 평균 검증 정확도: 0.9666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvPsr2a-AZuu"
      },
      "source": [
        "### cross_val_score\n",
        "- 폴드 세트 추출, 학습/예측, 평가를 한번에 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFTRLlBd1h6r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d0684ba-6a66-4f90-f132-cfa2e978db38"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "\n",
        "iris_data = load_iris()\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "data = iris_data.data\n",
        "label = iris_data.target\n",
        "\n",
        "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
        "print('교차 검증별 정확도:', np.round(scores, 4))\n",
        "print('평균 검증 정확도:', np.round(np.mean(scores), 4))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "교차 검증별 정확도: [0.98 0.94 0.98]\n",
            "평균 검증 정확도: 0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crn0TmhWA_Uo"
      },
      "source": [
        "### GridSearchCV\n",
        "- Classifier나 Regressor와 같은 알고리즘에 사용되는 하이퍼 파라미터를 순차적으로 입력하면서 편리하게 최적의 파라미터를 도출할 수 있는 방안을 제공한다.\n",
        "- 교차 검증과 최적 하이퍼 파라미터 튜닝을 한번에 진행한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LLkBgBZA_F1"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    iris_data.data,\n",
        "    iris_data.target,\n",
        "    test_size=0.2,\n",
        "    random_state=121\n",
        ")\n",
        "\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "parameters = {'max_depth': [1, 2 ,3], 'min_samples_split': [2, 3]}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "jNG_LvSXDIXK",
        "outputId": "1132b065-7d58-4c43-ff4f-d3be6ff21a87"
      },
      "source": [
        "# 하이퍼 파라미터들을 3개의 train, test set fold로 나눠서 테스트 수행\n",
        "# refit=True가 default, True이면 가장 좋은 파라미터 설정으로 재 학습 진행\n",
        "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True, return_train_score=True)\n",
        "\n",
        "# 붓꽃 Train 데이터로 param_grid의 하이퍼 파라미터들을 순차적으로 학습/평가\n",
        "grid_dtree.fit(X_train, y_train)\n",
        "\n",
        "# GridSearchCV 결과는 cv_results_ 라는 딕셔너리로 저장됨.\n",
        "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score',\n",
        "           'split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     params  ...  split2_test_score\n",
              "0  {'max_depth': 1, 'min_samples_split': 2}  ...               0.70\n",
              "1  {'max_depth': 1, 'min_samples_split': 3}  ...               0.70\n",
              "2  {'max_depth': 2, 'min_samples_split': 2}  ...               0.95\n",
              "3  {'max_depth': 2, 'min_samples_split': 3}  ...               0.95\n",
              "4  {'max_depth': 3, 'min_samples_split': 2}  ...               0.95\n",
              "5  {'max_depth': 3, 'min_samples_split': 3}  ...               0.95\n",
              "\n",
              "[6 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHwonxfnERw6"
      },
      "source": [
        "grid_dtree.cv_results_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b57lOZ8qEca_",
        "outputId": "1584f483-98d4-474a-e2ee-63ae437aaab1"
      },
      "source": [
        "print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
        "print('GridSearchCV 최고 정확도:', grid_dtree.best_score_)\n",
        "\n",
        "pred = grid_dtree.predict(X_test)\n",
        "print('테스트 데이터 세트 정확도:', accuracy_score(y_test, pred))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV 최적 파라미터: {'max_depth': 3, 'min_samples_split': 2}\n",
            "GridSearchCV 최고 정확도: 0.975\n",
            "테스트 데이터 세트 정확도: 0.9666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I4gGS69E0fB",
        "outputId": "cd5e983a-f05d-48bc-cbd7-e412d8bd4406"
      },
      "source": [
        "# GridSearchCV의 refit으로 이미 학습된 estimator 반환\n",
        "estimator = grid_dtree.best_estimator_\n",
        "\n",
        "pred = estimator.predict(X_test)\n",
        "print('테스트 데이터 세트 정확도:', accuracy_score(y_test, pred))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "테스트 데이터 세트 정확도: 0.9666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCjN-DsAFI9R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}